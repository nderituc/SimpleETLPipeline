{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17550334-7d61-4548-a525-fbc3a5ac6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Configuration\n",
    "# Use your own Configurations\n",
    "POSTGRES_CONN_STR = \"postgresql+psycopg2://username:password@localhost:5432/dbname\"\n",
    "SNOWFLAKE_CONN_STR = (\n",
    "    \"snowflake://username:password@account_identifier.region.cloud_provider/database/schema\"\n",
    "    \"?warehouse=warehouse_name&role=role_name\"\n",
    ")\n",
    "SOURCE_TABLE = 'Games'  # The table in PostgreSQL to extract from\n",
    "TARGET_TABLE = 'Games'    # The table in Snowflake to load into\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def extract_data_from_postgres():\n",
    "    \"\"\"Extracts data from a PostgreSQL database and stores it in a DataFrame.\"\"\"\n",
    "    logging.info(\"Starting data extraction from PostgreSQL.\")\n",
    "    try:\n",
    "        # Connect to PostgreSQL\n",
    "        postgres_engine = create_engine(POSTGRES_CONN_STR)\n",
    "        query = f\"SELECT * FROM {SOURCE_TABLE}\"\n",
    "        \n",
    "        # Load data into a DataFrame\n",
    "        df = pd.read_sql(query, postgres_engine)\n",
    "        logging.info(f\"Data extraction complete. Extracted {len(df)} rows.\")\n",
    "        \n",
    "        return df\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(\"Error during data extraction from PostgreSQL\", exc_info=True)\n",
    "        raise e\n",
    "    finally:\n",
    "        postgres_engine.dispose()\n",
    "\n",
    "def validate_data(df):\n",
    "    \"\"\"Validates the data before loading it into Snowflake.\"\"\"\n",
    "    logging.info(\"Validating data.\")\n",
    "    \n",
    "    # Check for null values\n",
    "    if df.isnull().values.any():\n",
    "        raise ValueError(\"Data contains null values. Validation failed.\")\n",
    "    \n",
    "    # Data type checks\n",
    "    if not pd.api.types.is_integer_dtype(df['year']):\n",
    "        raise ValueError(\"Year column contains non-integer values.\")\n",
    "    if not pd.api.types.is_string_dtype(df['round']):\n",
    "        raise ValueError(\"Round column contains non-string values.\")\n",
    "    if not pd.api.types.is_string_dtype(df['winner']):\n",
    "        raise ValueError(\"Winner column contains non-string values.\")\n",
    "    if not pd.api.types.is_string_dtype(df['opponent']):\n",
    "        raise ValueError(\"Opponent column contains non-string values.\")\n",
    "    if not pd.api.types.is_integer_dtype(df['winner_goals']):\n",
    "        raise ValueError(\"Winner_goals column contains non-integer values.\")\n",
    "    if not pd.api.types.is_integer_dtype(df['opponent_goals']):\n",
    "        raise ValueError(\"Opponent_goals column contains non-integer values.\")\n",
    "    \n",
    "    logging.info(\"Data validation passed.\")\n",
    "    return df\n",
    "\n",
    "def load_data_to_snowflake(df):\n",
    "    \"\"\"Appends validated data to an existing Snowflake table.\"\"\"\n",
    "    logging.info(\"Loading data to Snowflake.\")\n",
    "    try:\n",
    "        # Connect to Snowflake\n",
    "        snowflake_engine = create_engine(SNOWFLAKE_CONN_STR)\n",
    "        \n",
    "        # Append data to the target table in Snowflake\n",
    "        df.to_sql(\n",
    "            name=TARGET_TABLE,\n",
    "            con=snowflake_engine,\n",
    "            index=False,\n",
    "            if_exists='append',  # Appends data to the table\n",
    "            method='multi'       # Enables batch inserts\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Data loading to Snowflake completed successfully.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(\"Error during data loading to Snowflake\", exc_info=True)\n",
    "        raise e\n",
    "    finally:\n",
    "        snowflake_engine.dispose()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Orchestrates the ETL pipeline.\"\"\"\n",
    "    try:\n",
    "        # Step 1: Extract data into a DataFrame\n",
    "        df = extract_data_from_postgres()\n",
    "        \n",
    "        # Step 2: Validate data\n",
    "        validate_data(df)\n",
    "        \n",
    "        # Step 3: Append the DataFrame to Snowflake table\n",
    "        load_data_to_snowflake(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Pipeline failed.\", exc_info=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
