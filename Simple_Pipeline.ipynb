{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17550334-7d61-4548-a525-fbc3a5ac6df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 17:54:28,321 - INFO - Starting data extraction from PostgreSQL.\n",
      "2024-10-16 17:54:28,920 - INFO - Data extraction complete. Extracted 32 rows.\n",
      "2024-10-16 17:54:28,922 - INFO - Validating data.\n",
      "2024-10-16 17:54:28,925 - INFO - Data validation passed.\n",
      "2024-10-16 17:54:28,927 - INFO - Loading data to Snowflake.\n",
      "D:\\Anaconda3\\Lib\\site-packages\\snowflake\\sqlalchemy\\base.py:1068: SAWarning: The GenericFunction 'flatten' is already registered and is going to be overridden.\n",
      "  functions.register_function(\"flatten\", flatten)\n",
      "2024-10-16 17:54:40,593 - INFO - Snowflake Connector for Python Version: 3.12.2, Python Version: 3.12.4, Platform: Windows-11-10.0.22631-SP0\n",
      "2024-10-16 17:54:40,596 - INFO - Connecting to GLOBAL Snowflake domain\n",
      "2024-10-16 17:54:40,597 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-10-16 17:54:44,979 - INFO - Number of results in first chunk: 1\n",
      "2024-10-16 17:54:45,190 - INFO - Number of results in first chunk: 1\n",
      "2024-10-16 17:54:45,317 - INFO - Number of results in first chunk: 6\n",
      "2024-10-16 17:54:47,440 - INFO - Number of results in first chunk: 2\n",
      "2024-10-16 17:54:47,947 - INFO - Number of results in first chunk: 1\n",
      "2024-10-16 17:54:48,126 - INFO - Number of results in first chunk: 1\n",
      "2024-10-16 17:54:48,128 - INFO - Data loading to Snowflake completed successfully.\n",
      "2024-10-16 17:54:48,130 - INFO - closed\n",
      "2024-10-16 17:54:48,231 - INFO - No async queries seem to be running, deleting session\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# Configuration\n",
    "# Use own configurations\n",
    "POSTGRES_CONN_STR = 'postgresql+psycopg2://username:password@localhost:5432/dbname'\n",
    "SNOWFLAKE_CONN_STR = (\n",
    "    'snowflake://username:password@account_identifier.region.cloud_provider/database/schema?warehouse=warehouse_name&role=role_name'\n",
    ")\n",
    "SOURCE_TABLE = 'Games'  # The table in PostgreSQL to extract from\n",
    "TARGET_TABLE = 'Games'    # The table in Snowflake to load into\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def extract_data_from_postgres():\n",
    "    \"\"\"Extracts data from a PostgreSQL database and stores it in a DataFrame.\"\"\"\n",
    "    logging.info(\"Starting data extraction from PostgreSQL.\")\n",
    "    try:\n",
    "        # Connect to PostgreSQL\n",
    "        postgres_engine = create_engine(POSTGRES_CONN_STR)\n",
    "        query = f\"SELECT * FROM {SOURCE_TABLE}\"\n",
    "        \n",
    "        # Load data into a DataFrame\n",
    "        df = pd.read_sql(query, postgres_engine)\n",
    "        logging.info(f\"Data extraction complete. Extracted {len(df)} rows.\")\n",
    "        \n",
    "        return df\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(\"Error during data extraction from PostgreSQL\", exc_info=True)\n",
    "        raise e\n",
    "    finally:\n",
    "        postgres_engine.dispose()\n",
    "\n",
    "def validate_data(df):\n",
    "    \"\"\"Validates the data before loading it into Snowflake.\"\"\"\n",
    "    logging.info(\"Validating data.\")\n",
    "    \n",
    "    # Check for null values\n",
    "    if df.isnull().values.any():\n",
    "        raise ValueError(\"Data contains null values. Validation failed.\")\n",
    "    \n",
    "    # Data type checks\n",
    "    if not pd.api.types.is_integer_dtype(df['year']):\n",
    "        raise ValueError(\"Year column contains non-integer values.\")\n",
    "    if not pd.api.types.is_string_dtype(df['round']):\n",
    "        raise ValueError(\"Round column contains non-string values.\")\n",
    "    if not pd.api.types.is_string_dtype(df['winner']):\n",
    "        raise ValueError(\"Winner column contains non-string values.\")\n",
    "    if not pd.api.types.is_string_dtype(df['opponent']):\n",
    "        raise ValueError(\"Opponent column contains non-string values.\")\n",
    "    if not pd.api.types.is_integer_dtype(df['winner_goals']):\n",
    "        raise ValueError(\"Winner_goals column contains non-integer values.\")\n",
    "    if not pd.api.types.is_integer_dtype(df['opponent_goals']):\n",
    "        raise ValueError(\"Opponent_goals column contains non-integer values.\")\n",
    "    \n",
    "    logging.info(\"Data validation passed.\")\n",
    "    return df\n",
    "\n",
    "def load_data_to_snowflake(df):\n",
    "    \"\"\"Appends validated data to an existing Snowflake table.\"\"\"\n",
    "    logging.info(\"Loading data to Snowflake.\")\n",
    "    try:\n",
    "        # Connect to Snowflake\n",
    "        snowflake_engine = create_engine(SNOWFLAKE_CONN_STR)\n",
    "        \n",
    "        # Append data to the target table in Snowflake\n",
    "        df.to_sql(\n",
    "            name=TARGET_TABLE,\n",
    "            con=snowflake_engine,\n",
    "            index=False,\n",
    "            if_exists='append',  # Appends data to the table\n",
    "            method='multi'       # Enables batch inserts\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Data loading to Snowflake completed successfully.\")\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(\"Error during data loading to Snowflake\", exc_info=True)\n",
    "        raise e\n",
    "    finally:\n",
    "        snowflake_engine.dispose()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Orchestrates the ETL pipeline.\"\"\"\n",
    "    try:\n",
    "        # Step 1: Extract data into a DataFrame\n",
    "        df = extract_data_from_postgres()\n",
    "        \n",
    "        # Step 2: Validate data\n",
    "        validate_data(df)\n",
    "        \n",
    "        # Step 3: Append the DataFrame to Snowflake table\n",
    "        load_data_to_snowflake(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Pipeline failed.\", exc_info=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaac5f-0bf2-42f2-b34a-75f1b3c5dc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
